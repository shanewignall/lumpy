Probability is the likelihood that an event will happen. You can calculate probability if you know the number of outcomes of an event and the total number of possible outcomes. If you buy a raffle ticket and only 500 total tickets are sold, the probability of your ticket being selected is 1 in 500. If you buy five tickets, you increase the probability of having the winning ticket. Probability is the likelihood of a certain event happening. The probability of an event will always be between 0 and 1. The probability of two events occurring can be independent or dependent, depending on whether or not one event affects the probability of the other event. Events are mutually exclusive if they cannot occur together. Either one event outcome can happen or the other—but not both. Probability is the likelihood that an event will happen. An event is made up of one or more outcomes and is part of the total number of possible events that could occur. The two kinds of probability are classical and empirical. Classical probability is when each outcome is equally likely to happen. What is the probability of rolling a 5 using a standard number cube? With one 5 and 6 possible outcomes, the probability is . Empirical probability is based on observations of probability experiments. If a number cube is rolled 100 times, and a 5 is rolled 15 times, the empirical probability of rolling a 5 is . An event consists of one or more outcomes, and is a subset of the total number of possible events that could occur. The set of all possible outcomes in a probability experiment is referred to as the sample space . Probability refers to the likelihood of the occurrence of certain events. In our daily vocabulary, we often say, "What are the chances of that happening?" Or, "The odds of that happening are slim." There are two types of probability we will discuss in this course: classical and empirical. For example, suppose there were a red, blue, and yellow ball in a bag, and you were going to pull one ball out without looking. The event would be the color of the ball you pulled out (either red, blue, or yellow). But, the sample space would be red, blue, and yellow, which are all the possible outcomes of the pull. Classical or theoretical probability refers to the type of probability when each outcome is equally likely to occur. The classical probability of an event E is: If we flip a coin once, what is the probability of it showing heads? Using the formula, the numerator is the total number of ways of getting heads, which is 1, and the denominator is the total number of possible outcomes, which is 2. Thus, the probability of getting a head is: Empirical or statistical probability is based on observations obtained from probability experiments . The empirical probability that an event E will occur is: Where f is the frequency of event E occurring and n is the total frequency of the experiment, or : According to the law of large numbers , if an experiment is performed repeatedly, the empirical probability of an event will be close to its theoretical or actual probability. For example, the theoretical or actual probability of getting heads after tossing a coin is 50%. If a coin tossed 10 times shows heads 4 times, the empirical probability is 40%. However, if a coin is tossed 1000 times, based on the law of large numbers, the occurrence of getting heads will be approximately 500 times. According to this rule, the probability of an event E is always between 0 and 1. Mathematically, it is expressed as: The complement of an event E refers to the set of all outcomes in a sample space that are not included in an event E . It is denoted as E ' (pronounced E prime), and its probability is calculated as follows: P ( E ) = 1 - ( P(E ). For example, if there is a 60% probability of rain tonight, then the probability of no rain will be: P (no rain) = 1 – 0.6 = 0.4. Probability is the likelihood of the occurrence of certain events. The set of all possible outcomes is the sample space . The probability of an event is written as P ( E ). The complement of an event E is the set of possible outcomes in the sample space that are not contained in the event E . The two kinds of probability are as follows: Classical or theoretical probability is when each outcome is equally likely to occur. Empirical or statistical probability is based on observations from probability experiments. , where f is the frequency of event E occurring and n is the total frequency of the experiment. The empirical probability of an event approaches its classical or theoretical probability the more an experiment is performed. Often, two events are considered when calculating probability. If one event does not affect the probability of the other event occurring, the two events are independent . If one event does affect the probability of the other event, the events are dependent . Conditional probability is the probability of event B given that event A has already occurred: P(B / A) . Suppose you are 1 of 12 students who will make a presentation. The professor randomly draws names one at a time to determine the order of presenters. The probability of your name being drawn first is , but the probability of your name being drawn second given that it was not drawn first is ; third, ; and so on. The probability of your name being selected increases as more names are drawn because fewer names remain to draw from. In our previous probability examples, we were only dealing with one event. We only wanted to know the probability of some event, E , occurring. Often, we will have two events that we need to consider when calculating probability. Calculating the probability of A and B occuring together requires that we know what types of events are being considered: independent or dependent events. When one event does not affect the probability of occurrence of another event, the two events are considered independent. For example, getting a 2 after rolling a die and drawing an Ace from a deck of cards are independent events . Events that are not independent are considered dependent , that is, the probability of one event occurring is dependent upon another event. Conditional probability is the probability of an event B occurring, given that another event A has already occurred. It is denoted by P(B/ A) . For example, if you were to consider the odds of drawing a King from a deck of cards, the probability would be . If you drew a King the first time and did not replace the cad, the probability of drawing a King again would now be . There is one less card in the deck and one less King as well. However, if you did not draw a King the first time, the probability of drawing a King the second time (again without replacing the first card you drew) would be , your odds would continue to increase until you drew a King. The multiplication rule is used to determine the probability of occurrence of two events A and B in sequence. In other words, we use it to answer the question, "What is the probability of A and B occurring together?" The formula for the multiplication rule is represented as follows: A and B must be independent events that can occur together. If A and B are dependent events, the multiplication rule is: The organizers of a fundraising dinner decide to give out door prizes to the attendees. Out of the 500 people in attendance, the organizers choose 10 people at random for a big prize. They also choose 30 people at random for a smaller prize. Both groups of winners are chosen from the full list of attendees, so there is nothing to prevent a single person from being selected for both types of prize. The probability of any particular person winning the big prize is so The probability of any particular person winning a small prize is Let’s find the probability of any particular person winning both a big prize and a small prize. To begin with, we have to determine whether or not the events are independent. Because being selected for one type of prize does not affect the likelihood that an individual will be selected for the other, we can conclude that the events are independent. Since the events are independent, the multiplication rule tells us that So the probability of any particular person winning both prizes is . Ahmed’s grandfather has a jar of marbles and a jar of coins, and he allows Ahmed to take one item from each jar. The jar of marbles contains 30 marbles in total; 20 are red, 7 are blue, and 3 are yellow. The jar of coins contains 10 coins in total; 6 are pennies, 3 are dimes, and 1 is a quarter. If Ahmed chooses a coin and a marble at random, the probability that he will choose a yellow marble and a quarter is .01. The probability that he will draw a yellow marble and a quarter is .01. The yellow marble has a .1 chance of being chosen, the quarter also has a .1 chance of being chosen. .1 x .1 = .01 The probability of drawing an Ace the second time out of a deck of cards after not replacing the first one is 3/51. When considering the possibility of two events occurring, the events are independent if one event does not affect the probability of the other event. However, the events are dependent if one event does affect the probability of the other event. Conditional probability is the probability of an event B occurring, given that another event A has already occurred. Use the multiplication rule to determine the probability of events A and B occurring in sequence. If A and B are independent events: P ( A and B ) = P ( A ) · P ( B ) If A and B are dependent events: P ( A and B ) = P ( A ) · P ( B / A ) Events are mutually exclusive if they cannot occur together. Think of a mutually exclusive relationship. For example, if you are a member of the basketball team and your friend is a member of the volleyball team, you are mutually exclusive with your friend. That is, you do not compete together. Events that are mutually exclusive cannot occur together, that is, they have no outcomes in common. Events that can occur together are not mutually exclusive events. Consider a situation in which a university has both psychology and business departments. Some students are psychology majors only, others are business majors only, but there are also students who are both psychology and business majors. Thus, psychology and business majors are not mutually exclusive; a college student could be both at the same time. Now consider a normal deck of 52 playing cards. You can either draw a red card or a black card; a card cannot be both red and black. Therefore, red and black playing cards are mutually exclusive; you will never have a card that fits in both categories. Another example takes us back to our coin, with heads on one side and tails on the other. When we flip a coin, only one side will face up. Thus, heads and tails are mutually exclusive; they cannot appear at the same time when flipping only one coin. The addition rule is used to find the probability of the occurrence of event A or B. Mathematically, the addition rule is represented as follows: P(A or B) = P(A) + P(B) – P(A and B) If events are mutually exclusive, then the P ( A and B ) = 0. For example, what is the probability that the next card we draw from a full deck of cards will be a heart or a diamond? Mutually exclusive events have no outcomes in common. For example, an on/off switch has two possible outcomes: on or off. It cannot be both on and off. Use the addition rule to find the probability of the occurrence of event A or B . P ( A or B ) = P ( A ) + P ( B ) – P ( A and B ) If events are mutually exclusive, then P ( A and B ) = 0. Probability is used in areas, ranging from science and physics to lottery-drawing and statistics. Probability is the likelihood of certain events occurring. Probabilities may be independent or dependent, depending on if one event is affected by another event. If events are mutually exclusive, then they cannot occur together. In a basketball game, the home team will either win or lose the game. It cannot do both, and there are no ties in basketball. You may have heard the expression "graded on a bell curve" before. A bell curve , or normal curve , shows the normal distribution of a set of data. Most scores cluster around the mean, and half the data fall above the mean and half below the mean. Only a few scores will be extremely high or extremely low. Normal curves are used in education, scientific fields, and even for employee evaluations. Explore the shape and symmetry of a normal distribution, or bell curve. Understand and compute z-scores from raw data when given the mean and standard deviation. Use z-scores and the z-table to calculate areas under the normal distribution curve. The normal distribution is one of the most important distributions in probability theory. The graph of the normal distribution is called a normal curve , or a bell curve . All normal curves are "bell-shaped," but some normal curves are thinner and taller while others are shorter and wider. The spread of the data in relation to the mean determines how spread out the curve is. A continuous probability distribution is a probability distribution of a continuous random variable. Continuous random variables have an uncountable number of possible outcomes, including fractions and decimals, represented by an interval on the number line. This lesson will focus on the normal distribution , the most important continuous probability distribution in statistics. The normal distribution is the continuous probability distribution for a random variable, x. The graph of the normal distribution is called a normal curve, or a bell curve. There are several characteristics that hold true for ALL normal curves: The normal curve is symmetrical, that is, the right half is the mirror image of the left half. Half of the observations fall above the mean and half fall below the mean. Most of the observations cluster around the mean; there are fewer observations as the curve moves away from the mean. The mean, median, and mode are equal, that is, they are the same value. A normal curve approaches but never touches the x-axis. The total area under a normal curve is equal to 1. The mean and the standard deviation of a distribution determine the shape of the normal curve. While all normal curves will appear "bell-shaped," some normal curves are thinner and taller while others are shorter and wider. The smaller the standard deviation, the less spread out the data are. Thus, the narrower the normal curve will be. Remember that the total area under the curve is equal to 1. There are some other areas that are known to be true for all normal curves: Only .26% of the observations fall between 3 and 4 standard deviations from the mean, with the remaining .02% falling beyond 4 standard deviation units from the mean (-4 and 4). In a normal curve, 68% of observations fall between –1 and 1 standard deviations. All normal curves have a bell shape. Although some curves are thinner and taller while others are shorter and wider, the total area will always equal 1. This is true for all normal curves. The graph of the normal distribution is a bell curve , or normal curve . All normal curves have the same basic shape, but the mean and the standard deviation determine whether the curve is thinner and taller or shorter and wider. The smaller the standard deviation, the less spread out the data are, and the narrower the normal curve will be. Some characteristics are true for all normal curves: Standard scores allow comparisons between groups that would not normally be comparable. Scores are standardized so that they are based on the same normal distribution. The most commonly used standard score in statistics is the z-score . Even bone density measurements are given as z -scores so that no matter which machine and scale determined the initial measurement, the results can be compared against a reference value. There are an infinite number of normal distributions, each with its own mean and standard deviation. The standard normal distribution is a special case, with a set mean and a set standard deviation. The standard normal distribution is a distribution of standard scores . There are several ways to standardize scores. It requires that you convert the raw data to a scale with a set mean and a set standard deviation. For example, most standardized tests are standard scores: there's a set mean and a set standard deviation onto which all raw scores are rescaled. The IQ test, for example, has a mean of 100 and a standard deviation of 15. All raw scores collected from IQ tests are rescaled onto this standard scale. Standard scores are important for making comparisons across groups and data collection situations. They allow us to compare apples to oranges, that is, to compare data that otherwise would not be comparable. For example, perhaps we wanted to determine in which class a student was performing better. Let's say that Sue has an 85% in her Algebra course and a 90% in her English course. We cannot say that she is doing better in her English class just because it's the highest grade. Instead, we would need to rescale the scores onto the same scale so that they can be compared. The most commonly used standard score in statistics is the z-score, and is exactly what we would use here to answer this question. The z -score is a standard score with a mean of 0 and a standard deviation of 1. The use of z -scores allows us to compare data from one situation to data from another situation. The z -score distribution is a standard normal distribution. The z -score calculated for an observation equals the number of standard deviations that the given observation, or x , falls from the mean. We can take data that we collect, convert it to z -scores, and compare those z -scores to answer our questions. The formula for calculating z is: For our example started earlier, where we are trying to determine in which class Sue is better performing, we would first need to calculate Sue's z -score for each class and then compare the z -scores to answer the question. Now, compare the z -scores to determine in which class Sue is performing better. Remember that the z -score equals the number of standard deviations a given value x falls from the mean. Positive z -scores indicate that x falls above the mean; negative z -scores indicate that x falls below the mean. In Algebra, Sue falls above the mean since her z =.29 but in English, Sue falls below the mean since her z = -.67. So, even though Sue's average is higher in English, she is performing better in Algebra, and we know that because her z -score is higher for Algebra than for English. However, it should be evident to you that z -scores are very dependent on the mean and standard deviation of the group from which x comes. Calculation of z-score when mean and standard deviations are given. This table shows how we compare Sue's performance in Algebra and English using z-score. In Algebra, the mean is 84, Sue's performance is 85, and the standard deviation is 3.45. z equals 85 minus 84 divided by 3.45, which equals 1 divided by 3.45, which equals 0.29. In English, the mean is 92, Sue's performance is 90, and the standard deviation is 2.98. z equals 90 minus 92 divided by 2.98, which equals negative 2 divided by 2.98, which equals 0.67. Given a student's test grade in the form of a z -score, we can convert it back to the raw score using this formula. Let's revisit Sue, and her z = .29 in Algebra. We know that the class mean was 84 and the standard deviation was 3.45. Plug those values into the formula to determine Sue's raw score. x = 84 + .29(3.45) x = 84 + 1.0005 = 85.0005 = 85 Sue's score in Algebra was an 85. The z -score is a standard score with a mean of 0 and a standard deviation of 1. You collect raw data values and use the formula to convert them to z -scores to compare information. Formula for calculating z : , where x is the raw data value, is the mean of the group that x came from, and s is the standard deviation for that group. You can also calculate a raw score from a z -score: You can calculate probabilities using the z -table and z -scores. Because the normal curve, or bell curve , is symmetrical, the area under the curve is the same for both the positive and negative values of each z -score. You would use the same value for a z -score of –0.79 as you would for 0.79. Once we have z -scores, we can use the standard normal table to find out the area under the normal curve that corresponds to that z -score. To use the table, scroll down the columns with z at the top (there are several – just keep scrolling down until you find the z value you are looking for), then look to the column immediately to the right to see how much area under the curve falls between the mean and that z -score. The column next to that one indicates the proportion of the area that falls beyond that z -score. Because the normal curve is symmetrical, the table works for both positive and negative z -scores, that is, the area under the curve is the same for both the positive and negative forms of a particular z -score. We can use the table to determine how much area under the curve is captured by the z -scores that we calculate. Using our z -scores from Sue's classes, we find that the area under the curve between the mean and z = .29 is 0.1141 and that the area under the curve between the mean and z = -.67 is 0.2486. This is an example of a normal, bell-shaped curve for different values of z with the areas under the curve between z and the mean shaded and labeled (a) and the areas not between z and the mean shaded and labeled (c) to correspond to the data table under the curves. For z=.28, the area under the curve between z and the mean is .1103, and the area under the curve not between z and the mean is .3897. For z=.29, the area under the curve between z and the mean is .1141, and the area under the curve not between z and the mean is .3859. For z=.66, the area under the curve between z and the mean is .2454, and the area under the curve not between z and the mean is .2546. For z=.67, the area under the curve between z and the mean is .2486, and the area under the curve not between z and the mean is .2514. For z=.68, the area under the curve between z and the mean is .2517, and the area under the curve not between z and the mean is .2483. Perhaps we want to know what proportion of the area falls at or below z = 0.25. Sketch the curve and shade the appropriate area under the curve. Use the table to find the area that corresponds to z = 0.25. The proportion of the area under the curve that falls between the mean and z = 0.25 is 0.0987. This is not our answer!! This is only the area between the mean and our z -score. We want to know what proportion of the area under the curve falls at or below z = 0.25. Remember what we know about our curve. The normal curve is symmetrical, and half of the area falls above the mean and half falls below. So, in order to find our answer, we must add .50 (which represents the left half of the curve, that is, everything below the mean) to the .0987 that we found in the table (which represents the area from the mean to z = 0.25). Our final answer, then, is .5987. The proportion of the area under the curve that falls at or below z = 0.25 is .5987 or .60 (if we round our answer to two decimal places). Perhaps we want to know what proportion of the area of the curve falls above z = 1.25. Sketch the curve and shade the area we are trying to find. The first column of the table will give us the proportion of the area between the mean and z = 1.25, but that's not what we're interested in. The second column will give us the proportion of the area under the curve that falls beyond z = 1.25. That's what we want! So the proportion of the area under the curve that falls beyond z = 1.25 is .1056. What if we want to know what proportion of the area falls between z = -1.35 and z = .75? We follow similar steps as our earlier examples. Sketch the curve and shade the area we are trying to find. Use the table to find the area under the curve between the mean and z = -1.35 and between the mean and z = .75. z = -1.35: .4115 z = .75: .2734 Add together the two proportions to get the total area of the curve that falls between z = -1.35 and z = .75 .4115 + .2734 = .6849 What if we want to know what proportion of the area under the curve falls between z = -2.25 and z = -1.25? Sketch the curve and shade the area we are trying to find. Use the table to find the area under the curve between the mean and z = -2.25 and between the mean and z = -1.25. z = -2.25: .4878 z = -1.25: .3944 We now have to subtract the smallest area from the largest area to get our answer, because we're not interested in that chunk of area between the mean and z = -1.25. .4878 - .3944 = .0934 Area cannot be a negative number!! You will always subtract the smallest number from the largest number, and your answer will always be positive. By using the z-table you can find the value for z = 1.3, then subtract from 1 to get your answer. To find the proportion of the area that falls between two z-scores you would find the proportion under the curve for each z-score and subtract them. The standard normal table, or z-table , consists of three columns: Column 1: The z -score Column 2: The area under the curve between the mean and the z -score Column 3: The proportion of the area that falls beyond that z -score The illustrations at the top of the table reinforce what each of the three columns represents. To find the proportion of the area that falls between two z -scores, find the proportions for both z -scores and subtract them. You always subtract the smaller number from the larger number. Remember, area will always be positive. The normal distribution is a continuous probability distribution for a random variable x . The graph of the normal distribution is a normal curve, or bell curve. Whether the curve is thin and tall or short and wide depends on whether the standard deviation is small or large. An infinite number of normal distributions are possible. The standard normal distribution is a distribution of standard scores, also known as z -scores. By calculating z -scores from raw data, you can use those scores to compare data from different situations. The standard normal table, or z -table, displays the area under the curve for any given z -value. When using data collected from a sample population, you want to have a degree of confidence in the inferences that you make about the population as a whole. In statistics, you can calculate confidence intervals to minimize any sampling errors. Having confidence in the accuracy of inferences made about a population is important. Confidence intervals take into account the possibility of sampling errors. A formula can be used to construct a confidence interval when you know the standard deviation for a population. A separate, but similar, formula is used to construct confidence intervals when the standard deviation of a population is unknown. By knowing the sample size, you can easily find the degree of freedom and the necessary t-value to construct confidence intervals. Data are collected about a sample population to make inferences about the population as a whole. Having confidence in the accuracy of those inferences is important. Confidence intervals take into account the possibility of sampling errors. To construct a confidence interval for the mean, two methods are available. The first uses the standard deviation of the population ( ), and the second uses the standard deviation of the sample ( s ) because the population standard deviation is unknown. With this lesson, we enter the world of inferential statistics. Specifically, this lesson will use a sample statistic to estimate a population parameter. Recall that we don't really care about the information we gather from a sample, except for the information it can give us about the population of interest. We use samples to make inferences about the population. But we have to have some confidence in the accuracy of those inferences that we make. Confidence intervals allow us to do just that. Since we often use samples, sampling error is an issue. The Central Limit Theorem will help us deal with the sampling error that exists. The Central Limit Theorem loosely states that if we repeatedly choose random samples of size n from a population with a mean ( μ ) and a standard deviation &sigma;, the sampling distribution of sample means will have a mean equal to the population mean ( ) and a standard error equal to . The theorem also contends that as n increases, the sampling distribution will approach a normal distribution. So what? Well, the Central Limit Theorem gives us a formula we can use to calculate the standard error of the mean ( ), which is necessary in order to construct more accurate confidence intervals. When is known OR When is not known We will use the standard error of the mean to calculate confidence intervals. Sampling leads to sampling errors. You should assume the population mean and sample mean are not the same because of sampling error. You can use the central limit theorem to minimize any sampling error that exists. The central limit theorem states that if you repeatedly choose random samples of size n from a population, as n increases, the sampling distribution approaches a normal distribution. When the standard deviation of the population (&sigma;) is known: When (&sigma;) is not known: Based on the central limit theorem, you can use the formulas to calculate the standard error of the mean. You can then use the standard error of the mean to calculate confidence intervals. If you know the standard deviation of a population, you can construct confidence intervals to capture the true population mean with a certain degree of confidence. A confidence interval will have an upper limit and a lower limit. The upper limit is found by adding a certain amount to the sample mean, and the lower limit is found by subtracting a certain amount from the sample mean. Select the confidence level, usually 95% or 99%. A confidence level of 95% would mean that there is a 95% chance that the true population mean lies within the interval. A lower level would lower the confidence you have that the true population mean will be included in your interval. It isn't often that we know the standard deviation for the population, but don't know the mean. Although rare, this situation does exist. For example, standardized tests often have been rescaled to have a known mean and a known standard deviation for the population. The SAT has been standardized or rescaled to have a set population mean of 500 per section and a population standard deviation of 100. Using the SAT example, imagine that we work for a company that provides test preparation services to students planning to take the SAT. We want to determine if our training is helping students succeed on the examination. We randomly sample 300 students from our customer base and collect information about their performances on the math portion of the SAT exam. We determine that our sample has a mean of 610. We can use that mean to estimate the mean score for our population, that is, our entire customer base. We use the sample mean to construct a confidence interval that will capture the true population mean with a certain degree of confidence. So how do we construct this confidence interval? We construct the interval by adding a certain value to our sample mean to establish the upper limit of the interval and by subtracting a certain value from the sample mean to establish the lower limit of the interval. So how confident can we be in our interval? It depends! We typically calculate 95% or 99% confidence intervals since we want to be really sure we've captured the population mean. We could choose other levels of confidence, but lower values will lessen the amount of confidence we have in the fact that our true population mean falls within our interval. To calculate a 95% confidence interval using the SAT example, we do the following steps: Calculate the standard error of the mean. Our standard deviation is 100 and n = 300. Therefore, our standard error of the mean is 5.77. An example illustrating the steps for calculating standard error of a sample mean. Standard error of the mean equals standard deviation divided by the square root of n. In this example, standard error equals 100 divided by the square root of 300, which equals 100 divided by 17.32, which equals 5.77. Determine the value of z . Since we are calculating a 95% confidence interval, the value of z will be 1.96. Solve the formula. Our confidence interval is 598.69 to 621.31. Our concluding statement would go something like this: It is estimated with 95% confidence that the true mean of the population falls between 598.69 and 621.31. An example illustrating the steps for calculating upper and lower control limits a 95 percent confidence limits interval. Confidence Interval (CI) equals mean plus or minus z times the standard error of the mean. In this example, CI equals 610 plus or minus 1.96 times 5.77, which equals 610 plus or minus 11.31 which equals 621.31 and 598.69. When you know the standard deviation for a population, you can use the sample mean to construct a confidence interval. You want the interval to include the true population mean with a certain degree of confidence. To calculate a confidence interval when the standard deviation is known: Where: For a 95% confidence interval, use a z -value of 1.96. For a 99% confidence interval, use a z -value of 2.58. The ± symbol shows the upper and lower limits of the confidence interval. Adding to the sample mean establishes the upper limit of the interval, and subtracting the same amount from the sample mean establishes the lower limit of the interval. You can also construct confidence intervals when you don't know the standard deviation of a population. This type of scenario is much more likely. Your approach to constructing confidence intervals will be similar to your approach for finding confidence intervals when you did know the standard deviation. The two main differences are that you will use the sample standard deviation and that you won't be able to use z -values. What kind of trick is this, you ask? Isn't this the same formula as for the standard error of the mean? A standard deviation divided by the square root of n is exactly what we did to calculate the standard error of the mean: What's so different about this one that makes us call it the estimated standard error of the mean? Remember that when we calculate the standard deviation for a population, we divide the sum of the squared mean differences by n and take the square root, but when we calculate the standard deviation for a sample, we divide by n – 1. So, using the sample standard deviation in this formula for the estimated standard error of the mean already has an adjustment built into it to account for the fact that our sample contains error: Using the estimated standard error of the mean solves our first problem: the fact that &sigma; is unknown. Now, to solve the second issue: we can't always use the normal curve since we don't always have normally distributed data. To solve this issue, we have to rely on the family of t -distributions . The family of t -distributions is made up of several distributions. Just like a normal distribution, each t -distribution is symmetrical and has a mean of 0, but in this case there are many different t distributions and the exact shape of the distribution depends on sample size. When the sample size is small, the distribution, and so the curve, is relatively flat; when the sample size is large, the middle of the curve grows larger and the curve is less spread out. To calculate confidence intervals when σ isn't known, we will use a t value instead of a z value. The t value, just like z , is a point along the x-axis. We won't learn two magic numbers that always work with our confidence intervals like 1.96 and 2.58 worked for z . Instead, we have to use a table of critical values of the t distribution in order to locate the correct value for t to use in the calculation of confidence intervals. As mentioned earlier, we can calculate confidence intervals to any percent, but we tend to use 95% and 99% most often. So the columns of the table that we will use most often are the ones headed .05 (for calculating 95% confidence intervals) and .01 (for calculating 99% confidence intervals). The value we get from this table is the one we will plug in to the formula in place of t . This t-table shows values for a Two-Tailed test and a One-Tailed test at alpha levels of 0.5 and 0.1 for degrees of freedom from 1 to infinity. The values are as follows. Degrees of Freedom are labeled df. You use the t -distribution in the calculation of confidence intervals when the data are not normally distributed. In a t -distribution, when the sample size is large, the curve is usually higher in the middle, and the data is less spread out. Commonly, you will not know the standard deviation of the population when you want to estimate the mean of a population. If you don't know the standard deviation (&sigma;), you will need to use the sample standard deviation ( s ) in your confidence interval calculations. To calculate a confidence interval when the standard deviation is not known: Notice that z -values are replaced with t -values. Since the data may not be normally distributed, you can't use z -values. You will use values from a table listing the family of t -distributions. Even though each t -distribution is symmetrical and has a mean of 0, the exact shape of the distribution depends on sample size. When the sample size is small, the distribution and the curve are relatively flat. When the sample size is large, the middle of the curve grows larger and the curve is less spread out. The approach to constructing confidence intervals when the standard deviation is unknown involves t -values and degrees of freedom , or df . Degrees of freedom tell you how many of the observations are free to vary. If you know the number of subjects in the sample, you can use that information and t-tables to find the value of t for your particular situation. In order to use the Family of t Distributions (two-tailed) table, we must first calculate the degrees of freedom . The concept of degrees of freedom is fairly complex, and is something we'll see over and over in inferential statistics. Its precise meaning changes depending on the inferential test we are using, but it is generally an indication of how many of the observations in our distribution are free to vary, that is, to be any value whatsoever. For calculating confidence intervals, the degrees of freedom is equal to n - 1. In other words, given the mean of a distribution of n scores, n - 1 of the scores are free to vary. Here's an example of how this works. Let's assume that we have a sample of 10 scores with a maximum score of 10, and we know the mean score of this distribution is 7. The sum of the scores must be 70 in order to obtain a mean of 7 for this set of data. Thus, 9 ( n - 1) of the observations can be any value at all, but the tenth observation is restricted to what is needed in order for the total sum to be 70. Here's an illustration: ___+___+___+___+___+___+___+___+___+___ = 70 The first 9 values can be anything between 1 and 10. For example, let's assume that the first 9 values are: 5 + 8 + 7 + 9 + 4 + 7 + 9 + 5 + 6 = 60 Because the first 9 values sum to 60, the final value MUST be 10 in order to bring our total sum to 70 (which is what we need to end up with a mean of 7). The final observation is not free to vary; it has to equal 10. Since n - 1 observations are free to vary, the degrees of freedom for this example is 10 - 1 = 9. We will need to add in a couple more steps when we use t instead of z , since we now need to calculate the degrees of freedom and use it to find our value for t . Otherwise, the process is the same as what we've already learned. Let's work through a couple of examples. Calculate the 95% confidence interval for the following sample: = 22 s = 3.5 n = 65 Calculate the degrees of freedom. Identify the value for t from the table using the section under the Two-Tailed Test heading. Find the df in the far left column that is closest to 64 without going over. The closest value is 60. Now scroll over to the column with the level of significance of .05 since we are calculating a 95% confidence interval. The value for t that we will use is 2.000. Calculate the estimated standard error of the mean. Now we can use this information to construct the confidence interval. Thus, we are 95% confident that the true population mean falls between 21.14 and 22.86. Calculate the 99% confidence interval for the following sample. = 175 s = 15.78 n = 135 Calculate the degrees of freedom. Identify the value for t from the table using the section under the Two-Tailed Test heading. Find the df in the far left column that is closest to 134 without going over. The closest value is 120 NOT infinity (∞). Now scroll over to the column with the level of significance of .01 since we are calculating a 99% confidence interval. The value for t that we will use is 2.617. Calculate the estimated standard error of the mean. Now we can use this information to construct the confidence interval. Thus, we are 99% confident that the true population mean falls between 171.44 and 178.56. Constructing a confidence interval for the mean will not give us an exact estimate for the population mean. Instead, we have an interval within which we believe, to a certain level of confidence, the true population mean falls. You should know that the formula for constructing a confidence interval when the standard deviation of a population is unknown is . To find the value of t : You gather data from a population sample so that you can make inferences about the population. Whether the standard deviation of a population is known or unknown, the confidence intervals can be calculated so that you can, with a certain degree of confidence, say that the population mean will be included within a specific interval a certain percentage of the time. 
